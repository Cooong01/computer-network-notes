# 3.1 概述和运输层服务
- 运输层协议为运行在不同主机上的应用进程之间提供了==逻辑通信（logic communication）功能== （区别于物理通信）。
- 运输层协议在端系统而不是路由器中实现。
- 在发送端，运输层将从发送应用程序进程接收到的报文转换成运输层分组，也就是运输层==报文段（segment）==。方法（可能）是把应用层报文分为较小的块，并为每块加上一个运输层首部来生成运输层报文段。
- 各种物理实体涉及的层次，以及逻辑通信的体现：![[Pasted image 20231002232800.png]] 
## 3.1.1 运输层和网络层的关系
- 网络层为主机之间提供逻辑通信，而运输层为（不同）主机的不同进程之间提供逻辑通信。
- 非常不错的例子：[[计算机网络：自顶向下方法（原书第七版）.pdf#page=140&selection=98,0,177,1|计算机网络：自顶向下方法（原书第七版）, page 140]] 
- 显然运输层协议提供的服务明显受限于网络层协议提供的服务。但是*特别地*，即使网络层的服务有缺陷，运输层也能提供某些完善的服务。比如，即使网络协议不可靠，会使分组丢失、篡改和冗余，运输层也能提供可靠的数据传输服务。
## 3.1.2 因特网运输层概述
- 本书为了简化术语，把运输层分组称为==报文段（segment）==，网络层分组称为==数据报（datagram）==。
	- 关于术语在因特网文献的歧义：[[计算机网络：自顶向下方法（原书第七版）.pdf#page=140&selection=98,0,177,1|计算机网络：自顶向下方法（原书第七版）, page 140]] 
- 提前介绍：网络层协议：IP，也就是==网际协议==。IP为主机之间提供了逻辑通信，IP的服务模型是==尽力而为交付服务（best-effort delivery service）==。这意味着IP尽最大努力在主机之间交付报文段，但不做任何保证。不确保交付、不确保按序交付、不确保数据完整性。IP也被称为==不可靠服务（unreliable service）==。
- UDP和TCP最基础的责任：把两个端系统之间的IP交付服务扩展为运行在端系统上的两个进程之间的交付服务。把主机间交付扩展到进程间交付被称为==运输层的多路复用（transport-layer multiplexing）==与==多路分解（demultiplexing）==。
- 进程到进程的数据交付和差错检查是两种最低限度的运输层服务，也是UDP仅能提供的两种服务。
- TCP还提供其他集中服务，如==可靠数据传输（reliable data transfer）==、==拥塞控制（congestion control）==。
# 3.2 多路复用与多路分解
- 所有计算机网络都需要多路复用与多路分解。
- ==多路分解（demultiplexing）==：将运输层报文段中的数据交付到正确的套接字。
- ==多路复用（multiplexing）==：在源主机从不同套接字收集数据块，并为每个数据块封装上首部信息（在以后用于分解）从而生成报文段，然后将报文段传递到网络层。 
- 为了实现多路分解和多路复用，需要
	- 套接字有唯一标识符
	- 每个报文段有特殊字段来指示该报文段所要交付到的套接字
		- 这些特殊字段是：==源端口号字段（source port number field）==和==目的端口号字段（destination port number field）==。端口号是16比特的数，大小在0到65535之间，0到1023端口号被称为==周知端口号（well-known port number）==，它们被保留给诸如HTTP（80）和FTP（21）之类的周知应用层协议来使用。
		- 当开发一个新的应用程序时，必须为其分配一个端口号。
### 1. 无连接的多路复用与多路分解
- 通常，服务器端必须由开发者分配一个端口号，周知协议就分配周知端口号，不是周知协议就分配其他端口号。而客户端由运输层自动（透明地）分配端口号。
- 过程很好理解。[[计算机网络：自顶向下方法（原书第七版）.pdf#page=144&selection=342,0,346,13|计算机网络：自顶向下方法（原书第七版）, page 144]] 
- UDP的套接字由一个二元组来标识（一个目的IP地址和一个目的端口号）
### 2. 面向连接的多路复用与多路分解
- TCP套接字由一个四元组来标识（源IP地址、源端口号、目的IP地址、目的端口号）。
- 具有不同源IP地址或源端口号的报文段到达服务器时被定向到两个不同的套接字。
- 服务器新创建的套接字通过上面提到的四元组里的四个值来标识。如果后续到达的报文段与这四个字匹配，就被分配到这个套接字。
### 3. Web服务器与TCP
服务器通常只使用一个进程，为每个新的客户连接都创建一个新连接套接字的新线程（线程可看做一个轻量级的子进程）。也就是说，多个套接字可以对应同一个进程。
# 3.3 无连接运输：UDP
- 一个例子：DNS。查询主机在发送查询之后等待响应，如果没有收到响应，要么就试图向另一个名字服务器发送该查询，要么通知调用的应用程序它不能获得响应。
- 优点：
	- 传递迅速，没有拥塞控制机制，总是以最大速率发送。
	- 不需要建立连接，因此没有建立连接的时延。
		- HTTP中TCP连接的时延对下载Web文档的时延来说是一个重要因素。谷歌Chrome浏览器用QUIC协议（快速UDP因特网连接）将UDP作为其支撑运输协议，并在UDP之上的应用层协议里实现可靠性。
	- 无连接状态，不需要状态信息，不跟踪状态参数，因此某些特别需求的服务器能支持更多活跃的客户。
	- 分组首部开销小，TCP首部20字节，UDP8字节。
- 用途：远程文件服务器、流式多媒体、因特网电话、网络管理、DNS。
- UDP应用可以通过在应用程序自身中建立可靠性机制来实现可靠数据传输。
- UDP有争议，因为不控制拥塞，假如每个人都以很高码率看视频，就会造成路由器的分组溢出，每个人都大量丢包，而且造成TCP拥堵，TCP会话被挤垮。
## 3.3.1 UDP 报文段结构
![[Pasted image 20231003162422.png]] 
长度字段指首部加数据的字节数。检验和用来检查在该报文段中是否出现了差错。
首部有四个字段，每个字段两个字节（16比特）。
## 3.3.2 UDP 检验和
检验和，就是把所有16比特字（先把检验和本身设置为0000000000000000（16个0））求和后进行反码运算，每次求和得到位数大于16就回卷（回卷：把溢出的位的数作为单独的一个二进制数与除去溢出位的二进制数相加）。
当接收方拿到检验和时，就对所有16比特字求和（每次溢出回卷），如果和是1111111111111111（16个1），就代表分组中没有差错。
- 正常全是1的原因：对于接收方来说，拿到的检验和之外的数字的溢出回卷和与检验和本身互为反码，互为反码的俩数加在一起就会全是1。
- 为什么要提供检验和（差错检测）？因为源和目的之间不一定所有链路都有差错检测。且，在系统设计里面有一个被推崇的原则，叫做==端到端原则（end-end principle）==，这个原则表述为：如果某种功能必须基于端到端实现，与在较高级别提供这些功能的代价相比，在较低级别上设置的功能可能是冗余的或者几乎没有价值的。
	- 另一种表述：端到端原则是一种分布式系统中各模块间功能定位的设计原理，指从代价和性能的角度分析，在网络的最核心的部分应该只做数据的传输而不能去做一些其他的应用，而数据是否正确传输则应该放到应用层去检查和判断，从而保证互联网核心的简单性、可维护性和可扩展性。
	- 自己的*简单理解*：在较为底层的传输中如果有差错检测，这种差错检测是检测不到端本身导致的差错的。比如，如果端的硬盘出现问题，导致保存数据时产生了差错，那就必须由UDP自己提供差错检测才能检测到。
- UDP不提供差错恢复。它可以丢弃受损报文段或者给应用程序提出警告。其他的比如重传之类的事情就由应用程序自己解决。
# 3.4 可靠数据传输原理
可靠数据传输向上层实体提供的服务抽象是：数据可以通过一条可靠的信道进行传输。实现这种服务抽象的责任在于==可靠数据传输协议（reliable data transfer protocol）==的责任。这种协议默认位于其下层的传输是不可靠的。
- 本节讨论的理论适用于一般的计算机网络而不仅仅是因特网运输层。因此采用通用术语“分组”。
- 本节会慢慢迭代，开发一个可靠数据传输协议的发送方侧和接收方侧。
- 本节只考虑==单向数据传输（unidirectional data transfer）==的情况，也就是数据传输是从发送端到接收端的。可靠的==双向数据传输（bidirectional data transfer）==（也就是全双工数据传输）情况从概念上不会更难。
## 3.4.1 构造可靠的数据传输协议
### 1.  经完全可靠信道的可靠数据传输：rdt1.0
- 首先考虑最简单的情况：底层信道是完全可靠的。称此时的协议为rdt1.0。
- rdt1.0的发送方和接收方的==有限状态机（Finite-State Machine，FSM）==的定义：![[Pasted image 20231003174633.png]] 虚线箭头表示初始状态，实线箭头表示状态变迁，实横线之上表示引起变迁的事件，实横线之下表示事件发生时才去的动作。如果缺少动作或事件，用符号A去掉中间的横。
	- 这个有限状态机很简单，动作和事件名字都是自解释的。
### 2. 经具有比特差错信道的可靠数据传输：rdt2.0
首先考虑对于人类来说如何处理可能有差错的情形。打电话时，如果要口述几串电话号码，接收者在理解并记下每句话后都会说OK，如果没听清，就会要求重复一遍容易误解的话。这种口述报文协议使用了==肯定确认（positive acknowledgment）==与==否定确认（negative acknowledgement）==，这些控制使得报文接收方能够让发送方知道哪些内容被正确接收。在计算机网络环境中，基于这样的重传机制的可靠数据传输协议被称为==自动重传请求（Automatic Repeat reQuest）协议==。
- ARQ还需要另外三种协议功能来处理存在比特差错的情况。
	- 差错检测：需要一种机制，来让接收方检测到何时出现了比特差错。例如，前面提到的UDP检验和。这种机制本身会导致额外的比特（比如检验和）。
	- 接收方反馈：接收方要反馈信息给发送方。肯定确认（ACK）和否定确认（NAK）就是这种反馈的例子。rdt2.0协议将从接收方向发送方回送ACK和NAK分组。理论上，只需要一个比特长，也就是0小时NAK，1表示ACK。
	- 重传：接收方接收到代表NAK的分组时，就向发送方重传之前的分组。
- rdt2.0的FSM定义：![[Pasted image 20231004201303.png]] 
- 注意到，在这一版协议里，rdt2.0必须等待接收到ACK才能回到等待上层数据的状态。也就是说，在等待收到ACK之前，rdt2.0并不会从上层获得更多的数据，也不会发送新的一块数据。因此，rdt2.0这样的协议被称为==停等（stop-and-wait）==协议。
- 一个仍然存在的问题：我们没有考虑ACK或者NAK本身受损的情况。要解决这个问题，可能进而面临如下几个问题：
	- 第一，就像人类，如果说话的听者没听清，说“请再说一遍”，但是可能说话者没听清这句话。他可能继续说“你说什么？”。这句话有两个可能的含义：一是说话者上文继续的内容，二是说话者在询问听者在说什么。此时，听者不明白到底要做什么。
	- 第二，引入检验和。对于不会丢失分组，只会出现分组损坏的信道，这个方式可以直接解决问题。
	- 第三，当发送方接到受损含糊不清的ACK或者NAK分组时，直接重传。然而，这会引入==冗余分组（duplicate packet）==。这同样导致了如第一中的一个问题，即接收方不知道这个分组是重传的分组还是后继的分组。
- 最终解决方案：简单的方法，被几乎所有现有的数据传输协议，包括TCP，采用。
	- 在数据分组中添加一个新的字段，让发送方对其数据分组编号，也就是把这个数据分组的==序号（sequence number）==放在这个字段。只要检查序号，就可以确定这个分组是否是一个重传。只需要一个比特（模2运算即可，也就是，对二进制的每一位相加，不考虑进位、借位，奇数个1相加是1，偶数个1相加是0）。接收方要判断重传，只需要看看刚收到的分组序号和上一个分组序号是不是相同即可。
	- ![[Pasted image 20231004210641.png]] 
	- ![[Pasted image 20231004210652.png]] 
### 3. 经具有比特差错的丢包信道的可靠数据传输：rdt3.0
考虑丢包，需要面对两个问题：丢包检测和丢包后的处理。其中，丢包后的处理可以用检验和、序号、ACK分组、重传来解决。关注前一个问题。
- 假设让发送方负责检测和恢复丢包，那么发送方只能在一段规定时间未收到任何响应后认为丢包了。此时就重传。不管此时可能发生了：
	- 1.发送分组到达接收方以及接收方发送ACK或者NAK时延过高
	- 2.发送的分组丢失
	- 3.接收方发回的ACK或者NAK丢失
- 为了实现一定时间的设定，需要引入==倒计数定时器（countdown timer）==。围绕这个定时器，发送方需要做到：
	- 1.每次发送一个分组时都启动一个定时器
	- 2.定时器中断的时候进行响应
	- 3.终止定时器
- rdt3.0的发送方FSM：
- ![[Pasted image 20231004212118.png]] ![[Pasted image 20231004212935.png]] 此处重点关注d情况，这个情况体现了重复接收到ACK1的情况，但是左边最后两行（发送ACK1、什么也不做）可能有误。应该只为“什么也不做”。根据abc的规律，最后一个箭头对应的动作不被显示，所以此处最后一行指的是左侧收到的倒数第二个箭头。
## 3.4.2 流水线可靠数据传输协议
停等协议中，发送方的大量时间花在等待上，造成有效吞吐量极低。此时需要流水线模型，也就是一直把分组向外传输，不等待。
![[Pasted image 20231004214745.png]] 此时面临几个问题：
- 必须增加序号范围，不能只是1位，因为每个输送中的分组必须有一个唯一的序号。
- 发送方和接收方必须能缓存一些分组。发送方缓存未被确认的分组，以备重传，接收方缓存已经正确接收的分组。
- 差错恢复可以有两种方式：
	- ==回退N步（Go-Back-N，GBN）==
	- ==选择重传（Selective Repeat，SR）==
## 3.4.3 回退N步
![[Pasted image 20231004215142.png]] 
- 其中不可用的序号必须在未被确认的分组已经得到确认时才能继续往下开放为可用。这样就限制了未确认分组和将被发送的分组的最大允许数。限制的原因之一是流量控制。
- 长度为N的窗口不断往下滑动，N被称为==窗口长度（window size）==，GBN协议也常被称为==滑动窗口协议（sliding-window protocol）==。
- 序号实际上是首尾相接的，一个k位的序号范围为0到(2^k)-1，0和(2^k)-1相邻。设计序号的运算必须使用模2^k运算。
现在我们可以有一个基于ACK，没有NAK的GBN协议的发送方和接收方的FSM，称为扩展FSM（因为增加了变量base和nextseqnum可以自定义）：
![[Pasted image 20231004220219.png]] 
GBN发送方必须响应三种类型的事件：
- 上层的调用：收到上层调用时，首先检查发送窗口是否满了，没满就发，并更新变量。满了就告诉上层满了，上层可能过一会儿再试。实际情况中，发送方更可能会缓存由于满了而发不了的数据，或者使用同步机制（一个信号变量）来让上层只有在窗口没满的时候才调用。
- 收到ACK：对序号为n的分组的确认采取==累计确认（cumulative acknowledgment）==的方式，这表明接收方正确接收序号为n及之前的所有分组。
- 超时事件：超时就重传所有已经发送但是还没确认过的分组。一旦收到一个ACK并且还有没确认的分组就重启定时器。没有未被确认的分组就停止计时器。此时出现现象：多个分组公用一个接收器。
GBN接收方只需要：
- 按序收到最新分组就为这个分组发一个ACK，并把数据交付到上层。
- 其余任何情况，都直接丢掉分组（这样就不需要缓存失序分组了。而且按照GBN的规则，失序的分组还会被重新发过来一遍。），并为最后一个按序收到的分组重发一个ACK（这句话同时代表：不给失序的分组发送ACK。这就会导致其在发送方看起来超时了）。
这一系列思想，是==基于事件的编程（event-based programming）==。
## 3.4.4 选择重传
回退N步会导致带宽被大量不必要进行的分组重传充斥，而且导致效率变低。==选择重传（SR）==解决这个问题。
SR接收方会确认一个正确接收的分组，而不管是否按次序。失序的分组会被识别出来，然后放到缓存里，直到它前面的分组被正确接收，然后一起交付给上层。
- SR的发送方的事件以及响应：![[Pasted image 20231004224137.png]] 与GBN不同，SR的定时器需要给每个分组都设定。收到ACK后，ACK对应分组的序号等于基序号才向前移动，此时注意：一直移动到最小的未确认分组处。
- SR的接收方事件以及响应：![[Pasted image 20231004224437.png]] 只要记住：基序号就是最小的那个期待但是还没收到的分组的序号。*当收到序号等于基序号且在窗口内的分组*，就把这个分组以及往后的序号连续的那些分组一起往上层交付，并且把窗口往下移动到下一个最小的那个期待但是还没收到的分组的序号。*当收到的分组大于基序号*，就缓存下来。*当收到的分组小于基序号*，就对这个分组发一个ACK。其他情况，忽略收到的分组。
- SR操作：![[Pasted image 20231004230323.png]] 
- 窗口长度必须小于等于序号空间大小的一半。否则，接收方可能会面临一些极端条件，比如不知道收到的序号代表的分组究竟是新的分组还是重传的分组。
对3.4节的总结：![[Pasted image 20231004230653.png]] 
- 一个额外的问题：某个分组可能在网络中滞留，并且会滞留足够长的时间，以至于属于它的旧序号空间的序号全部用完了，接收方早已来到了新的序号空间，而它就成了一个可能造成正确的错误的分组。实际应用的解决方法是：通过嘉定一个分组在网络中的“存活”时间不会超过某个固定最大时间量来做到这一点。高速TCP中，通常被假定为3分组左右。
# 3.5 面向连接的运输：TCP
## 3.5.1 TCP连接
TCP被称为是==面向连接的（connection-oriented）==，因为一个应用程序向另一个应用程序发送数据之前，两个进程必须先握手，也就是先发送预备报文段，来确保数据传输的参数，包括初始化与TCP相关的许多状态变量。
- 连接指的是逻辑连接，只保留在端系统中，而不存在网络核心中。没有进行实质的连接。
- TCP连接总是==点对点（point-to-point）==的，只能一对一，不可能一对多，多对多。
- ==三次握手（three-way handshake）==：客户先发送一个特殊TCP报文段，服务器用另一个特殊TCP报文段响应，最后客户再发第三个特殊报文段来响应。前两个报文段不包含应用层数据，第三个报文段可以包含应用层数据。
- 数据通过客户套接字后就被TCP引导到==发送缓存（send buffer）==里（接收端也有接收缓存），发送缓存是三次握手期间设置的。TCP在方便的时候把数据从缓存里拿出来传递到网络层。拿出来的数据量受限于==最大报文段长度（Maximum Segment Size，MSS）==，MSS通常根据本地发送主机发送的最大链路层帧长度（==最大传输单元（Maximum Transmission Unit，MTU）==）来设置。同时要保证一个TCP报文段封装在一个IP数据报里时加上TCP/IP首部长度（通常40字节）适合单个链路层帧。以太网和PPP链路层协议都有1500字节的MTU，所以MSS典型值是1460（*MSS说的不是英文原文那样的东西，而是指的是在报文段里应用层数据的最大长度，不包括首部*）目前有多种探测出路径MTU（可以从源到目的地的所有链路上发送的最大链路层帧）的方法，能用来设置MSS。
- TCP给每块客户数据配上一个TCP首部，从而形成多个==TCP报文段（TCP segment）==，然后传给网络层。
- 发送缓存与接收缓存：![[Pasted image 20231004233059.png]] 
- TCP的连接包括：一台主机上的缓存、变量和与进程连接的套接字、另一台主机上的另一组缓存、变量和与进程连接的套接字。
## 3.5.2 TCP报文段结构
![[Pasted image 20231004233419.png]]
（图示意思是，宽是32比特，除了数据和选项之外，每段结构的长度可以按照占宽的比例来看出来。）
包括：
- 源端口号
- 目的端口号
- 检验和字段（checksum field）
- 序号字段（sequence number field），32比特
- 确认号（acknowledgment number field），32比特
- 首部长度字段（header length field），4比特
- 接收窗口字段（receive window field），16比特
- 选项字段（options field）：可选，变长。发/接双方协商MSS时或者高速网络当做窗口调节因子使用
- 标志字段（flag field）其中，实践中PSH、URG和紧急数据指针并不用。![[Pasted image 20231004234605.png]] 
由于选项字段往往是空的，所以TCP首部一般是20字节（按图里的，5行\*32/8）。
### 1. 序号和确认号
- TCP把数据看作是无结构、有序的字节流。序号建立在字节流之上而不是报文段的序列之上。一个报文段的序号就是该报文段首字节的字节流编号。比如一个数据流是500000字节，MSS是1000字节，假设第一个报文段编号是0（初始序号可以随机选择），第二是1000，第三是2000。
- 确认号：用来表达期望从对方接收到的下一个字节的序号。如果接到了这个字节以后的字节，那么下一次发送报文仍然期望这一个字节的序号。TCP只确认流中到第一个丢失字节为止的字节，所以TCP被称为提供==累积确认（cumulative acknowledgment）==。
- TCP没有明确规定失序到达的报文段该怎么处理。TCP编程人员自己实现，选择直接丢弃或者缓存。
### 2. Telnet：序号和确认号的一个学习案例
- Telnet：用于远程登录的流行应用层协议，运行在TCP之上。（现在多用SSH，因为SSH有加密，Telnet没有。）
- 流程：![[Pasted image 20231007165524.png]]  首先客户发出报文，起始序号为42，期待服务器发回起始序号为79的报文，然后服务器发回起始序号为79的报文，确认号为43，表示已经成功收到字节42及以前的报文，等待字节43的出现。然后用户发回起始序号为42的报文，期待服务器发回起始序号为80的报文。注意到最后一次报文段里没有数据但仍然有序号，这是因为TCP存在序号字段，一定要填。
- 对客户到服务器的数据的确认被装载在一个承载服务器到客户的数据的报文段中，这种确认被认为是被==捎带（piggybacked）==在服务器到客户的数据报文段中的。
## 3.5.3 往返时间的估计与超时
### 1. 估计往返时间
==样本RTT（SampleRTT）== 就是从某报文段被发出（即交给IP）到对该报文段的确认被收到之间的时间量。TCP只在一段时间内给某个已发送但还没被确认的报文段估计SampleRTT，而且不为已被重传的报文段计算SampleRTT，只为传输一此的报文段测量SampleRTT。
- SampleRTT总是波动的，因此相对准确的估计需要一些平均公式。比如，TCP根据以下公式来更新EstimatedRTT（RTT均值）![[Pasted image 20231007224148.png]] 一个推荐的α值是0.125
- 接近现在的样本加权更多，统计学观点称之为==指数加权移动平均（Exponential Weighted Moving Average，EWMA）==。指数一词指的是一个给定SampleRTT的权值在更新的过程中呈指数型快速衰减。
- 测量RTT的偏差DevRTT用如下公式：![[Pasted image 20231007225655.png]] β的推荐值为0.25。SampleRTT波动小，则DevRTT值小。反之则大。
### 2. 设置和管理重传超时间间隔
重传的超时间间隔应该大于EstimatedRTT，SampleRTT波动较大就余量大一些，波动小就余量小一些。
TCP确定重传超时间间隔的方法：![[Pasted image 20231007230027.png]] 推荐的初始TimeoutInterval值是1秒，出现超时后，TimeoutInterval值将加倍，再出现就再加倍。直到收到报文段，再重新使用上述公式。
## 3.5.4 可靠数据传输
之前假定每个已经发送但没确认的报文段都与一个定时器相关联，但定时器的管理却涉及相当大的开销，因此推荐只使用单一的重传定时器。TCP遵循单一定时器。
- 简化的TCP发送方：![[Pasted image 20231007233125.png]] 此时的定时器过期间隔为TimeoutInterval，由上面的公式算出。
### 1. 一些有趣的情况
看图就行了
![[Pasted image 20231007233743.png]]![[Pasted image 20231007233747.png]]![[Pasted image 20231007233753.png]] 
### 2. 超时间隔加倍
这是一种拥塞控制。之前讲过，此处没有特别的内容。
### 3. 快速重传
TCP不使用否定确认，只有ACK。
![[Pasted image 20231007234329.png]]
发送方收到3个冗余ACK就执行==快速重传（fast retransmit）==，也就是在定时器过期之前就重传丢失的报文段。快速重传的TCP可用如下代码代替“简化的TCP发送方”之中的ACK收到事件：![[Pasted image 20231007234651.png]] 
### 4. 是回退N步还是选择重传
TCP的确认是累积式的。许多TCP会将正确接收但失序的报文段缓存起来。TCP的一种修改意见：==选择确认（selective acknowledgment）==，允许TCP接收方有选择地确认失序报文段，而不是累计确认最后一个正确接受的有序报文段。当这个机制和选择重传机制结合起来使用，TPC看起来就像通常的SR协议。
## 3.5.5 流量控制
接收方将数据放入缓存，但是应用程序可能要很久之后才去读取该数据，这会造成缓存溢出。TCP为应用程序提供==流量控制服务（flow-control service）==来消除发送方使接收方缓存溢出的可能性。流量控制是一个速度匹配服务，也就是发送方发送速率与接收方应用程序的读取速率相匹配。这与拥塞控制的操作相似但是动机不同。*很多书将流量控制与庸俗控制混淆*
TCP让发送方维护一个称为==接收窗口（receive window）==的变量来提供流量控制。通俗的说，接收窗口用于指示接收方还有多少可用的缓存空间。TCP是全双工通信，所以连接两端的发送方都各自维护一个接收窗口。
然后，定义一些内容：![[Pasted image 20231008104307.png]] rwnd是动态的。![[Pasted image 20231008104833.png]] 
接收主机通过在报文段中把当前rwnd值放进接收窗口字段来通知发送主机自己在这个连接的缓存中还有多少可用空间。发送主机轮流跟踪两个变量，LastByteSent和LastByteAcked，前者减去后者即得到发送但还未确认的数据量，把这个数据量控制在rwnd以内，就保证了发送方不会使接收方接收缓存溢出，也就是：![[Pasted image 20231008105025.png]]
- 一个小问题：当接收方的接收缓存已经满了，rwnd=0，此时发送方就会一直不发新的报文，接收方在应用程序把缓存清理之后也不会发出新的报文，就导致新的数据不会再发送。
	- 解决这个问题，TCP规范要求：当接收方的接收窗口为0时，发送方继续发送只有一个字节数据的报文段。
UDP不提供流量控制。
## 3.5.6 TCP连接管理
TCP建立和拆除连接的过程：
==三次握手（three-way handshake）==：
- 第一步：客户TCP向服务器TCP发送一个特殊TCP报文段（==SYN报文段==），不包含应用层数据，首部SYN位被置为1，随机选择一个初始序号（client_isn）放在序号字段。
- 第二步：包含SYN报文段的IP数据报到达服务器，服务器从数据报里提取出TCP SYN报文段，为这个TCP连接分配缓存和变量，然后向客户发出允许连接的报文段，也不包含应用层数据，首部SYN位被置为1，确认号字段被置为client_isn + 1，随机选择自己的初始序号（server_isn），放在序号字段。这个报文段叫做==SYNACK报文段（SYNACK segment）==。
- 第三步：客户收到SYNACK报文段之后为该连接分配缓存和变量，再发送一个报文段，确认字段为server_isn + 1，SYN位被置为0，本次报文段可以携带应用层数据。
一条TCP连接的两个进程中的任何一个都可以终止这个连接。
- 过程：发送方向接收方发送TCP报文段，首部的FIN位被置为1
- 接收方收到后发送确认报文段
- 然后接收方再发送终止报文段，FIN同样被置为1
- 最后客户收到终止报文段后发送确认报文段。此时两个主机用于这条连接的资源都被释放。
- 服务器端TCP的典型状态序列：![[Pasted image 20231010171323.png]] 
## 3.6.1 拥塞原因与代价
### 1. 情况1：两个发送方和一台具有无限大缓存的路由器
![[Pasted image 20231010171451.png]] 
![[Pasted image 20231010171823.png]] 

在这种理想化的情况下，我们已经发现了拥塞网络的一种代价，就是当分组的到达速率接近链路容量时，分钟经历巨大的排队时延。
### 2. 情况2：两个发送方和一台具有有限缓存发的路由器
网络的==攻击载荷（offered load）==：运输层向网络中发送报文段（含有初始数据或重传数据）的速率。![[Pasted image 20231010171953.png]]![[Pasted image 20231010172220.png]] 网络拥塞代价2：发送方必须执行重传以补充因为缓存溢出 而丢弃的分组。
网络拥塞代价3：发送方在遇到大延时时所进行的不必要重传会引起路由器利用其链路带宽来转发不必要的分组副本
### 情况3:4个发送方和具有有限缓存的多台路由器及多条路径
![[Pasted image 20231010172424.png]] ![[Pasted image 20231010172428.png]] 代价4：路由器由于拥塞而丢弃分组的另一代价，即当一个分组沿一条路径被丢弃时，每个上游路由器用于转发该分组到丢弃该分组而使用的传输容量最终被浪费掉了。
## 3.6.3 拥塞控制方法
- 端到端拥塞控制：TCP通过观察丢包来判断
- 网络辅助的拥塞控制：路由器向发送方提供网络拥塞状态反馈信息。两种方式：![[Pasted image 20231010172838.png]] 
# 3.7 TCP拥塞控制
- 第一，TCP发送方如何限制它向连接发送流量的速率
	- ==拥塞窗口（congestion window）（cwnd）==：限制了发送方中未被确认的数据量，间接限制了发送方的发送速率。*拥塞窗口总是在接到返回报文之后才更新，所以至少需要一段RTT（往返时间），因此速率被限制在cwnd/RTT（字节/秒）*
- 第二，TPC发送方如何感知它到目的地之间的路径上存在拥塞
	- 我们将TCP发送方的“丢包事件‘定义为：要么出现超时，要么收到来自接收方的3个冗余ACK。
- 第三，当发送方感知到拥塞时，采用何种算法来改变其发送速率
	- 收到确认的时间越短，cwnd长度越迅速增大，反之越慢增大。这个机制是因为TCP使用确认来出发或计时增大它的拥塞窗口长度，因此TCP是==自计时（self-clocking）==的。
	- 原则1：一个丢失报文段表意味着拥塞，因此当丢失报文段时应当降低TCP发送方的速率。
	- 原则2：一个确认报文段指示该网络正在向接收方交付发送方的报文段，因此，对先前未确认报文段的确认到达时，能够增加发送方的速率。
	- 原则3：带宽探测。根据原则2，速率加大直到发现原则1后减少并再一段时间后再加大，反复探测最大带宽。
- ==TCP拥塞控制算法（TCP congestion control algorithm）==：![[Pasted image 20231010182810.png]] 
### 1.慢启动
- 初始有一个MSS为较小值，以最大长度报文段发送，然后每当传输的报文段被首次确认就加倍MSS。直到①发现超时就把cwnd设为1，重启慢启动，并且ssthresh（慢启动阈值）设为cwnd/2.②当检测到ssthresh和cwnd一样时，就结束慢启动，TCP转移到拥塞避免模式。③检测到3个冗余ACK，执行一种快速重传并进入快速恢复模式。
- 慢启动并不慢，此阶段发送速率以指数增长。
### 2.拥塞避免
- 进入拥塞避免状态，cwnd的值处于上一次遇到拥塞时的一半，距离拥塞不远，因此TCP不便按照指数模式增长，而是采用保守方法，每个RTT只将cwnd的值增加一个MSS。一种方法是对于TCP发送方无论何时到达一个新的确认，就将cwnd增加一个MSS长度的字节。此时增长是线性的。
- 结束拥塞避免的线性增长：出现超时时，与慢启动情况一样。当出现三个冗余ACK事件，TPC把cwnd值减半，ssthresh值记为cwnd值的一半，接下来进入快速恢复状态。
### 3.快速恢复（非必须）
- 收到每个冗余ACK，cwnd值增加一个MSS。当对于丢失报文段的一个ACK到达时，TCP在降低cwnd后进入拥塞避免状态。如果超时，就执行慢启动一样的动作，并迁移到慢启动状态。丢包事件出现时，cwnd值被设置为一个MSS，并且ssthresh的值设置为cwnd的一半。
### 4. TCP拥塞控制：回顾
TCP拥塞控制被总结为：==加性增、乘性减（Additive-Increase，Multiplicative-Decrease，AIMD）==。![[Pasted image 20231011222129.png]] 

### 5. 对TCP吞吐量的宏观描述
假设连接持续期间W（每次丢包时的窗口长度）和RTT不变。由于每次丢包窗口长度减半，而且窗口长度线性增大，所以有：
![[Pasted image 20231011222443.png]] 
### 6. 经高带宽路径的TCP
为了取得10Gbps的吞吐量，对丢包率L有如下公式：
![[Pasted image 20231012084826.png]] 
## 3.7.1 公平性
公平性的理解：对K条TCP连接，假设都经过一段R bps的瓶颈链路，假设没有UDP流量通过该瓶颈链路，每条连接平均传输速率接近R/K，就认为该拥塞控制机制是公平的。
### 1. 公平性和UDP
UDP不公平。现在有研究是开发一种因特网中的拥塞控制机制，阻止UDP流量不断压制因特网吞吐量的情况。
### 2. 公平性和并行TCP连接
TCP公平问题没有完全解决。一个应用程序可能并行使用多条TCP连接，比如浏览器。
## 3.7.2 明确拥塞通告：网络辅助拥塞控制
最近对于IP和TCP的扩展方案已经提出并实现和部署，这个方案允许网络明确向TCP发送方和接收方发出拥塞信号，这种形式的网络辅助用三个控制被称为==明确拥塞通告（Explicit Congestion Noitification，ECN）。==![[Pasted image 20231012222351.png]] 在网络层，IP数据报首部的服务类型字段中的两个比特用于ECN。当接收主机中的TCP接到数据报包含ECN拥塞指示，就在ACK报文段里设置ECE（明确拥塞通告回显）比特。发送方收到之后就减半拥塞窗口，然后在下一个要发出的报文段首部设置CWR（拥塞窗口缩减）比特。
- 除了TCP以外的其他运输层协议也可以把ECN信号利用起来。
==数据报拥塞控制协议（Datagram Congestion Control Protocol，DCCP）==就提供了一种低开销、类似UDP的不可靠服务，也利用了ECN。
==DCTCP（数据中心TCP）==是专门为数据中心网络设计的TCP版本，也用了ECN。
# 3.8 小结
事实上，链路层、网络层、运输层或运输层协议都可以提供可靠数据传输。